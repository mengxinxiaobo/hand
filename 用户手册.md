# 汉语手指字母识别软件 - 用户手册

## 📖 目录

1. [软件简介](#软件简介)
2. [系统要求](#系统要求)
3. [安装指南](#安装指南)
4. [快速开始](#快速开始)
5. [详细使用说明](#详细使用说明)
6. [手势说明](#手势说明)
7. [功能特点](#功能特点)
8. [常见问题](#常见问题)
9. [故障排除](#故障排除)
10. [技术说明](#技术说明)

---

## 软件简介

本软件是一个基于计算机视觉和机器学习的汉语手指字母（手语字母）识别系统。通过摄像头实时捕获手部动作，使用 MediaPipe 进行手部关键点检测，并采用机器学习模型识别30个不同的手语字母手势。

### 支持的字母

- **26个英文字母**: A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z
- **4个汉语拼音声母**: ZH, CH, SH, NG

**总计：30个手势**

---

## 系统要求

### 硬件要求

- **摄像头**: 内置或外接 USB 摄像头
- **处理器**: 支持 Python 3.12 的 CPU（推荐 Apple Silicon 或 Intel Core i5 及以上）
- **内存**: 至少 4GB RAM（推荐 8GB 或更多）
- **存储空间**: 至少 500MB 可用空间

### 软件要求

- **操作系统**: 
  - macOS 11.0 或更高版本
  - Windows 10/11
  - Linux (Ubuntu 18.04+)
- **Python**: Python 3.12 或更高版本
- **依赖库**: 见 `requirements.txt`

---

## 安装指南

### 步骤 1: 检查 Python 版本

打开终端（Terminal），运行：

```bash
python --version
```

确保版本为 Python 3.12 或更高。如果未安装，请访问 [python.org](https://www.python.org/) 下载安装。

### 步骤 2: 克隆或下载项目

如果您使用 Git：

```bash
git clone <项目地址>
cd sign_language_recognition
```

或直接下载项目压缩包并解压。

### 步骤 3: 安装依赖

在项目目录下运行：

```bash
pip install -r requirements.txt
```

**注意**: 如果遇到依赖冲突，建议使用虚拟环境：

```bash
# 创建虚拟环境
python -m venv venv

# 激活虚拟环境
# macOS/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# 安装依赖
pip install -r requirements.txt
```

### 步骤 4: 验证安装

运行以下命令验证关键库是否安装成功：

```bash
python -c "import cv2; import mediapipe; import numpy; print('安装成功！')"
```

---

## 快速开始

### 首次使用（需要训练模型）

1. **收集训练数据**:
   ```bash
   python data_collector.py
   ```
   按照提示为每个手势收集 100 个样本。

2. **训练模型**:
   ```bash
   python train_model.py
   ```
   等待训练完成，模型将保存为 `gesture_model.pkl`。

3. **运行识别程序**:
   ```bash
   python main.py
   ```

### 已训练模型

如果已有训练好的模型，直接运行：

```bash
python main.py
```

---

## 详细使用说明

### 一、数据收集 (`data_collector.py`)

数据收集是训练模型的第一步，需要为每个手势收集足够的样本。

#### 操作步骤

1. **启动数据收集工具**:
   ```bash
   python data_collector.py
   ```

2. **收集数据流程**:
   - 程序会按顺序提示您做出每个手势（从 A 开始）
   - 将手放在摄像头前，做出当前提示的手势
   - 当屏幕上显示 "Press 's' to save" 时，按 **'s'** 键保存样本
   - 每个手势需要收集 **100 个样本**
   - 可以按 **'n'** 键跳过当前手势
   - 按 **'q'** 键退出

3. **数据收集技巧**:
   - 保持手势清晰、标准
   - 在不同角度、不同距离下收集样本（提高模型鲁棒性）
   - 确保手部完全在摄像头视野内
   - 在良好的光照条件下进行

4. **完成收集**:
   - 收集完所有 30 个手势后，数据会自动保存到 `training_data/` 目录
   - 文件包括：
     - `features.npy`: 特征数据
     - `labels.npy`: 标签数据

#### 数据收集界面说明

- **绿色文字**: 当前手势名称和样本进度
- **绿色线条**: 检测到的手部关键点和连接
- **黄色提示**: "Press 's' to save" - 可以保存样本
- **红色提示**: "No hand detected" - 未检测到手部

### 二、模型训练 (`train_model.py`)

使用收集的数据训练识别模型。

#### 操作步骤

1. **启动训练**:
   ```bash
   python train_model.py
   ```

2. **训练过程**:
   - 程序会自动加载 `training_data/` 目录下的数据
   - 如果数据不存在，会提示是否生成示例数据（仅用于测试）
   - 训练过程可能需要几分钟，请耐心等待
   - 训练完成后会显示：
     - 模型准确率
     - 详细的分类报告（每个手势的精确率、召回率等）
     - 最重要的特征索引

3. **训练结果**:
   - 模型保存为 `gesture_model.pkl`
   - 控制台会显示测试集准确率
   - 建议准确率在 **70% 以上** 才能获得较好的识别效果

#### 训练参数说明

- **测试集比例**: 20%（80% 用于训练，20% 用于测试）
- **模型类型**: 随机森林（Random Forest）
- **树的数量**: 300 棵
- **最大深度**: 20 层

### 三、手势识别 (`main.py`)

使用训练好的模型进行实时手势识别。

#### 操作步骤

1. **启动识别程序**:
   ```bash
   python main.py
   ```

2. **使用界面**:
   - 摄像头窗口会自动打开
   - 将手放在摄像头前
   - 做出手语字母手势
   - 识别结果会实时显示在屏幕上

3. **界面说明**:
   - **绿色线条**: 检测到的手部关键点和骨骼连接
   - **绿色文字**: 识别结果（置信度 > 50%）
   - **橙色文字**: 识别结果（置信度 ≤ 50%，可能不准确）
   - **红色文字**: "No hand detected" - 未检测到手部

4. **退出程序**:
   - 按 **'q'** 键退出

#### 识别技巧

- **保持手势稳定**: 每个手势保持 2-3 秒
- **适当距离**: 手部与摄像头距离约 30-50 厘米
- **良好光照**: 确保手部清晰可见
- **背景简洁**: 避免复杂背景干扰
- **手势标准**: 按照手势指南做出标准手势

---

## 手势说明

### A-Z 字母手势

| 字母 | 手势描述 |
|------|---------|
| **A** | 握拳，拇指向上伸直 |
| **B** | 手掌张开向前，四指并拢向上，拇指收拢 |
| **C** | 手指弯曲成 C 形，拇指稍弯曲 |
| **D** | 食指向上伸直，其他手指和拇指握拳 |
| **E** | 手掌张开，所有手指和拇指并拢，水平向右 |
| **F** | 食指和中指并拢伸直，水平向右，其他手指握拳 |
| **G** | 仅食指伸直，水平向右，其他手指握拳 |
| **H** | 食指和中指并拢向上伸直，其他手指握拳 |
| **I** | 仅小指向上伸直，其他手指握拳 |
| **J** | 小指伸直，然后向下向左弯曲，形成 J 形 |
| **K** | 食指和中指向上分开成 V 形，拇指放在两指根部之间 |
| **L** | 拇指和食指伸直形成 L 形，其他手指握拳 |
| **M** | 握拳，拇指收在食指、中指、无名指下方 |
| **N** | 握拳，拇指收在食指、中指下方 |
| **O** | 所有手指和拇指弯曲形成圆形 |
| **P** | 食指向下，中指水平向右，交叉在食指上方 |
| **Q** | 食指和拇指形成小圆圈，其他三指向上伸直 |
| **R** | 食指和中指交叉，水平向右 |
| **S** | 握拳，拇指放在食指和中指指节前方 |
| **T** | 握拳，拇指放在食指和中指之间 |
| **U** | 手掌向前，食指和中指并拢向上，其他手指握拳 |
| **V** | 手掌向前，食指和中指向上分开成 V 形 |
| **W** | 手掌向前，食指、中指、无名指向上分开成 W 形 |
| **X** | 食指在指节处向下弯曲成钩状 |
| **Y** | 拇指和小指伸直向外，形成 Y 形 |
| **Z** | 食指伸直，在空中划 Z 形（右-左下-右） |

### 汉语拼音声母手势

| 声母 | 手势描述 |
|------|---------|
| **ZH** | 食指、中指、无名指并拢伸直，水平向右 |
| **CH** | 食指和拇指形成圆圈，其余三指向上伸直并稍分开 |
| **SH** | 握拳，拇指放在食指上方 |
| **NG** | 四指（食指、中指、无名指、小指）并拢伸直，水平向右，拇指收拢 |

### 手势演示建议

- 参考 `gesture_guide.md` 文件获取更详细的描述
- 可以在网上搜索"手语字母"查看视频教程
- 确保手势标准、清晰，便于识别

---

## 功能特点

### 1. 实时识别
- 基于摄像头实时捕获手部动作
- 低延迟识别（通常 < 100ms）
- 流畅的用户体验

### 2. 高精度检测
- 使用 MediaPipe 进行手部关键点检测
- 检测 21 个手部关键点
- 支持单手检测

### 3. 智能特征提取
- 77 维综合特征向量
- 包括相对坐标、角度、距离等多种特征
- 自动归一化处理

### 4. 机器学习模型
- 随机森林分类器（300 棵树）
- 支持 30 个手势类别
- 置信度评估

### 5. 结果平滑
- 使用历史记录平滑预测结果
- 减少识别抖动
- 提高识别稳定性

### 6. 可视化界面
- 实时显示手部关键点
- 显示识别结果和置信度
- 颜色编码（绿色=高置信度，橙色=低置信度）

---

## 常见问题

### Q1: 识别准确率很低怎么办？

**A**: 可能的原因和解决方法：

1. **训练数据不足**:
   - 确保每个手势至少收集 100 个样本
   - 在不同角度、距离下收集数据

2. **手势不标准**:
   - 参考手势指南，确保手势标准
   - 重新收集数据

3. **光照条件差**:
   - 在明亮、均匀的光照下使用
   - 避免强光直射或阴影

4. **模型未训练**:
   - 确保已运行 `train_model.py` 训练模型
   - 检查 `gesture_model.pkl` 文件是否存在

### Q2: 无法检测到手部？

**A**: 检查以下事项：

1. **摄像头权限**: 确保已授予摄像头访问权限
2. **摄像头连接**: 检查摄像头是否正常工作
3. **手部位置**: 确保手部完全在摄像头视野内
4. **光照条件**: 确保有足够的光照
5. **背景干扰**: 使用简洁的背景

### Q3: 训练模型时出错？

**A**: 可能的原因：

1. **数据文件缺失**: 确保已运行 `data_collector.py` 收集数据
2. **数据格式错误**: 删除 `training_data/` 目录，重新收集数据
3. **依赖库问题**: 检查是否安装了所有依赖库

### Q4: 如何提高识别准确率？

**A**: 建议：

1. **增加训练数据**: 每个手势收集 200-300 个样本
2. **数据多样性**: 在不同条件下收集数据（角度、距离、光照）
3. **手势标准**: 确保手势清晰、标准
4. **重新训练**: 收集更多数据后重新训练模型

### Q5: 支持双手识别吗？

**A**: 当前版本仅支持单手识别。如需双手识别，需要修改代码。

### Q6: 可以在 Windows/Linux 上使用吗？

**A**: 可以。确保：
- Python 3.12+
- 安装了所有依赖库
- 摄像头正常工作

---

## 故障排除

### 问题 1: 导入错误

**错误信息**: `ImportError: No module named 'cv2'`

**解决方法**:
```bash
pip install opencv-python
```

### 问题 2: 摄像头无法打开

**错误信息**: `无法打开摄像头`

**解决方法**:
1. 检查摄像头是否被其他程序占用
2. 检查摄像头权限设置
3. 尝试更改摄像头索引（在代码中将 `cv2.VideoCapture(0)` 改为 `cv2.VideoCapture(1)`）

### 问题 3: 模型文件不存在

**错误信息**: `模型文件不存在`

**解决方法**:
1. 运行 `python train_model.py` 训练模型
2. 确保 `gesture_model.pkl` 文件存在

### 问题 4: 依赖冲突

**错误信息**: `ERROR: ResolutionImpossible`

**解决方法**:
1. 使用虚拟环境隔离依赖
2. 检查 `requirements.txt` 中的版本要求
3. 更新 pip: `pip install --upgrade pip`

### 问题 5: 识别结果不稳定

**解决方法**:
1. 确保手势稳定，保持 2-3 秒
2. 检查光照条件
3. 确保手部完全在视野内
4. 重新训练模型（使用更多数据）

---

## 技术说明

### 架构概述

```
摄像头输入
    ↓
MediaPipe 手部检测
    ↓
关键点提取（21个点）
    ↓
特征提取（77维特征向量）
    ↓
随机森林分类器
    ↓
识别结果 + 置信度
```

### 技术栈

- **计算机视觉**: OpenCV, MediaPipe
- **机器学习**: scikit-learn (Random Forest)
- **数据处理**: NumPy
- **编程语言**: Python 3.12

### 特征提取详情

提取的 77 维特征包括：

1. **相对坐标特征** (42维): 相对于手腕的归一化坐标
2. **手指长度特征** (5维): 各手指指尖到指根的距离
3. **手指角度特征** (4维): 相邻手指之间的角度
4. **手指伸直度特征** (5维): 手指伸直程度比率
5. **手部中心距离特征** (21维): 各关键点到手部中心的距离

### 模型参数

- **算法**: Random Forest (随机森林)
- **树的数量**: 300
- **最大深度**: 20
- **最小分割样本数**: 5
- **最小叶子样本数**: 2

### 性能指标

- **识别速度**: 通常 < 100ms/帧
- **准确率**: 取决于训练数据质量（通常 70-85%+）
- **支持类别**: 30 个手势

---

## 联系与支持

如有问题或建议，请：

1. 查看本文档的"常见问题"和"故障排除"部分
2. 检查项目文档和代码注释
3. 提交 Issue 或 Pull Request

---

## 更新日志

### v1.0 (当前版本)

- ✅ 支持 30 个手语字母识别
- ✅ 实时摄像头识别
- ✅ 数据收集工具
- ✅ 模型训练功能
- ✅ 可视化界面
- ✅ 77 维特征提取
- ✅ 随机森林分类器（300 棵树）

---

**祝您使用愉快！** 🎉


